{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ceefaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "BASE_DIR = \"dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a27a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique slot types: 39\n",
      "\n",
      "=== Slot Frequency Ranking ===\n",
      "object_type               3341\n",
      "object_name               3087\n",
      "playlist                  2201\n",
      "timeRange                 2096\n",
      "rating_value              2057\n",
      "artist                    2020\n",
      "music_item                1767\n",
      "city                      1435\n",
      "restaurant_type           1426\n",
      "spatial_relation          1292\n",
      "rating_unit               1182\n",
      "playlist_owner            1167\n",
      "best_rating               1101\n",
      "party_size_number         1082\n",
      "state                     1063\n",
      "object_select             1031\n",
      "country                   900\n",
      "movie_name                861\n",
      "service                   801\n",
      "movie_type                723\n",
      "year                      660\n",
      "location_name             619\n",
      "entity_name               612\n",
      "sort                      576\n",
      "condition_temperature     497\n",
      "object_location_type      492\n",
      "condition_description     476\n",
      "restaurant_name           359\n",
      "party_size_description    330\n",
      "object_part_of_series_type 324\n",
      "geographic_poi            307\n",
      "current_location          290\n",
      "served_dish               275\n",
      "cuisine                   222\n",
      "track                     217\n",
      "album                     190\n",
      "facility                  167\n",
      "poi                       149\n",
      "genre                     147\n"
     ]
    }
   ],
   "source": [
    "def iter_all_json_files():\n",
    "    patterns = [\n",
    "        os.path.join(BASE_DIR, \"*\", \"train_*_full.json\"),\n",
    "        os.path.join(BASE_DIR, \"*\", \"validate_*.json\"),\n",
    "    ]\n",
    "    paths = []\n",
    "    for p in patterns:\n",
    "        paths.extend(glob.glob(p))\n",
    "    return paths\n",
    "\n",
    "def load_examples(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        content = json.loads(f.read())\n",
    "\n",
    "    if isinstance(content, list):\n",
    "        return content\n",
    "    if isinstance(content, dict) and \"utterances\" in content:\n",
    "        return content[\"utterances\"]\n",
    "    if isinstance(content, dict) and len(content) == 1:\n",
    "        val = next(iter(content.values()))\n",
    "        if isinstance(val, list):\n",
    "            return val\n",
    "\n",
    "    raise ValueError(f\"Unexpected JSON: {path}\")\n",
    "\n",
    "# Count slot frequencies\n",
    "slot_counter = Counter()\n",
    "\n",
    "for path in iter_all_json_files():\n",
    "    examples = load_examples(path)\n",
    "    for ex in examples:\n",
    "        for seg in ex[\"data\"]:\n",
    "            if \"entity\" in seg:\n",
    "                slot_counter[seg[\"entity\"]] += 1\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_slots = sorted(slot_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Total unique slot types: {len(sorted_slots)}\\n\")\n",
    "\n",
    "print(\"=== Slot Frequency Ranking ===\")\n",
    "for slot, count in sorted_slots:\n",
    "    print(f\"{slot:25s} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate SNIPS train/test JSON files\n",
    "\n",
    "def iter_snips_files(split: str):\n",
    "    if split == \"train\":\n",
    "        pattern = os.path.join(BASE_DIR, \"*\", \"train_*_full.json\")\n",
    "    elif split == \"test\":\n",
    "        pattern = os.path.join(BASE_DIR, \"*\", \"validate_*.json\")\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train' or 'test'\")\n",
    "\n",
    "    for path in glob.glob(pattern):\n",
    "        filename = os.path.basename(path)\n",
    "        name_part = filename.split(\"_\", 1)[1]\n",
    "        intent = (\n",
    "            name_part.replace(\"_full.json\", \"\").replace(\".json\", \"\")\n",
    "        )\n",
    "        yield intent, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9472bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a SNIPS JSON file\n",
    "\n",
    "def load_examples(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        text = f.read()\n",
    "    content = json.loads(text)\n",
    "\n",
    "    if isinstance(content, list):\n",
    "        return content\n",
    "    if isinstance(content, dict) and \"utterances\" in content:\n",
    "        return content[\"utterances\"]\n",
    "    if isinstance(content, dict) and len(content) == 1:\n",
    "        only_value = next(iter(content.values()))\n",
    "        if isinstance(only_value, list):\n",
    "            return only_value\n",
    "\n",
    "    raise ValueError(f\"Unexpected JSON format: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5078ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique slot types: 39\n",
      "\n",
      "=== Slot Frequency Ranking ===\n",
      "object_type               3341\n",
      "object_name               3087\n",
      "playlist                  2201\n",
      "timeRange                 2096\n",
      "rating_value              2057\n",
      "artist                    2020\n",
      "music_item                1767\n",
      "city                      1435\n",
      "restaurant_type           1426\n",
      "spatial_relation          1292\n",
      "rating_unit               1182\n",
      "playlist_owner            1167\n",
      "best_rating               1101\n",
      "party_size_number         1082\n",
      "state                     1063\n",
      "object_select             1031\n",
      "country                   900\n",
      "movie_name                861\n",
      "service                   801\n",
      "movie_type                723\n",
      "year                      660\n",
      "location_name             619\n",
      "entity_name               612\n",
      "sort                      576\n",
      "condition_temperature     497\n",
      "object_location_type      492\n",
      "condition_description     476\n",
      "restaurant_name           359\n",
      "party_size_description    330\n",
      "object_part_of_series_type 324\n",
      "geographic_poi            307\n",
      "current_location          290\n",
      "served_dish               275\n",
      "cuisine                   222\n",
      "track                     217\n",
      "album                     190\n",
      "facility                  167\n",
      "poi                       149\n",
      "genre                     147\n"
     ]
    }
   ],
   "source": [
    "# Count slot frequencies\n",
    "slot_counter = Counter()\n",
    "\n",
    "for path in iter_all_json_files():\n",
    "    examples = load_examples(path)\n",
    "    for ex in examples:\n",
    "        for seg in ex[\"data\"]:\n",
    "            if \"entity\" in seg:\n",
    "                slot_counter[seg[\"entity\"]] += 1\n",
    "\n",
    "# Sort by frequency (descending)\n",
    "sorted_slots = sorted(slot_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Total unique slot types: {len(sorted_slots)}\\n\")\n",
    "\n",
    "print(\"=== Slot Frequency Ranking ===\")\n",
    "for slot, count in sorted_slots:\n",
    "    print(f\"{slot:25s} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab53d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_to_token_rows_bio(intent, example, sentence_id):\n",
    "    segments = example[\"data\"]\n",
    "\n",
    "    utterance = \"\"\n",
    "    entity_spans = []\n",
    "    cursor = 0\n",
    "\n",
    "    # Build full utterance and record spans\n",
    "    for seg in segments:\n",
    "        text = seg[\"text\"]\n",
    "        if \"entity\" in seg:\n",
    "            slot = seg[\"entity\"]\n",
    "            start = cursor\n",
    "            end = cursor + len(text)\n",
    "            entity_spans.append((start, end, slot))\n",
    "        utterance += text\n",
    "        cursor = len(utterance)\n",
    "\n",
    "    # Whitespace tokenization with char spans\n",
    "    word_tokens = []\n",
    "    i = 0\n",
    "    length = len(utterance)\n",
    "\n",
    "    while i < length:\n",
    "        if utterance[i].isspace():\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        start = i\n",
    "        while i < length and not utterance[i].isspace():\n",
    "            i += 1\n",
    "        end = i\n",
    "\n",
    "        raw_token = utterance[start:end]\n",
    "        clean_token = raw_token.strip(string.punctuation)\n",
    "\n",
    "        if clean_token:\n",
    "            word_tokens.append((clean_token, start, end))\n",
    "\n",
    "    # Assign BIO tags\n",
    "    rows = []\n",
    "    for token_id, (token, start, end) in enumerate(word_tokens):\n",
    "\n",
    "        # find overlapping entity spans\n",
    "        matching = []\n",
    "        for ent_start, ent_end, slot_name in entity_spans:\n",
    "            if not (end <= ent_start or start >= ent_end):\n",
    "                matching.append((ent_start, ent_end, slot_name))\n",
    "\n",
    "        if not matching:\n",
    "            tag = \"O\"\n",
    "        else:\n",
    "            ent_start, ent_end, slot_name = matching[0]\n",
    "\n",
    "            span_indices = [\n",
    "                idx for idx, (_, s, e) in enumerate(word_tokens)\n",
    "                if not (e <= ent_start or s >= ent_end)\n",
    "            ]\n",
    "\n",
    "            if token_id == span_indices[0]:\n",
    "                tag = f\"B-{slot_name}\"\n",
    "            else:\n",
    "                tag = f\"I-{slot_name}\"\n",
    "\n",
    "        rows.append({\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"token_id\": token_id,\n",
    "            \"intent\": intent,\n",
    "            \"utterance\": utterance.strip(),\n",
    "            \"token\": token,\n",
    "            \"slot\": tag\n",
    "        })\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61374c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build stratified train/val split and convert examples into word-level BIO rows\n",
    "\n",
    "def build_train_val():\n",
    "    meta_examples = []  # list of (intent, example, sentence_id)\n",
    "    sentence_id = 0\n",
    "\n",
    "    # Load all training examples first\n",
    "    for intent, path in iter_snips_files(\"train\"):\n",
    "        examples = load_examples(path)\n",
    "        for ex in examples:\n",
    "            meta_examples.append((intent, ex, sentence_id))\n",
    "            sentence_id += 1\n",
    "\n",
    "    intents = [x[0] for x in meta_examples]\n",
    "\n",
    "    # Stratified split\n",
    "    train_meta, val_meta = train_test_split(\n",
    "        meta_examples,\n",
    "        test_size=0.1,\n",
    "        stratify=intents,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Convert train split to word-level BIO rows\n",
    "    train_rows = []\n",
    "    for new_sid, (intent, example, _) in enumerate(train_meta):\n",
    "        rows = example_to_token_rows_bio(intent, example, new_sid)\n",
    "        train_rows.extend(rows)\n",
    "\n",
    "    # Convert val split\n",
    "    val_rows = []\n",
    "    offset = len(train_meta)\n",
    "    for new_sid, (intent, example, _) in enumerate(val_meta):\n",
    "        rows = example_to_token_rows_bio(intent, example, offset + new_sid)\n",
    "        val_rows.extend(rows)\n",
    "\n",
    "    return pd.DataFrame(train_rows), pd.DataFrame(val_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c74ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build split (test)\n",
    "\n",
    "def build_test():\n",
    "    all_rows = []\n",
    "    sentence_id = 0\n",
    "\n",
    "    for intent, path in iter_snips_files(\"test\"):\n",
    "        examples = load_examples(path)\n",
    "        for ex in examples:\n",
    "            rows = example_to_token_rows_bio(intent, ex, sentence_id)\n",
    "            all_rows.extend(rows)\n",
    "            sentence_id += 1\n",
    "\n",
    "    return pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a17e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NER: (110572, 6)\n",
      "Val   NER: (12191, 6)\n",
      "Test  NER: (6318, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>intent</th>\n",
       "      <th>utterance</th>\n",
       "      <th>token</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>Play the playlist, A Mis Niños de 30.</td>\n",
       "      <td>Play</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>Play the playlist, A Mis Niños de 30.</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>Play the playlist, A Mis Niños de 30.</td>\n",
       "      <td>playlist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>Play the playlist, A Mis Niños de 30.</td>\n",
       "      <td>A</td>\n",
       "      <td>B-playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>Play the playlist, A Mis Niños de 30.</td>\n",
       "      <td>Mis</td>\n",
       "      <td>I-playlist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id     intent                              utterance  \\\n",
       "0            0         0  PlayMusic  Play the playlist, A Mis Niños de 30.   \n",
       "1            0         1  PlayMusic  Play the playlist, A Mis Niños de 30.   \n",
       "2            0         2  PlayMusic  Play the playlist, A Mis Niños de 30.   \n",
       "3            0         3  PlayMusic  Play the playlist, A Mis Niños de 30.   \n",
       "4            0         4  PlayMusic  Play the playlist, A Mis Niños de 30.   \n",
       "\n",
       "      token        slot  \n",
       "0      Play           O  \n",
       "1       the           O  \n",
       "2  playlist           O  \n",
       "3         A  B-playlist  \n",
       "4       Mis  I-playlist  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate final CSVs\n",
    "\n",
    "train_df, val_df = build_train_val()\n",
    "test_df = build_test()\n",
    "\n",
    "print(\"Train NER:\", train_df.shape)\n",
    "print(\"Val   NER:\", val_df.shape)\n",
    "print(\"Test  NER:\", test_df.shape)\n",
    "\n",
    "train_df.to_csv(\"dataset/snips_ner_train.csv\", index=False)\n",
    "val_df.to_csv(\"dataset/snips_ner_val.csv\", index=False)\n",
    "test_df.to_csv(\"dataset/snips_ner_test.csv\", index=False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e48ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album entities in test_df: 6\n",
      "Album entities in test_df: 195\n"
     ]
    }
   ],
   "source": [
    "def count_entities_bio(df, slot_name):\n",
    "    counts = 0\n",
    "    for sid, group in df.groupby(\"sentence_id\"):\n",
    "        prev = \"O\"\n",
    "        for tag in group[\"slot\"]:\n",
    "            if tag.startswith(f\"B-{slot_name}\"):\n",
    "                counts += 1\n",
    "    return counts\n",
    "\n",
    "print(\"Album entities in test_df:\", count_entities_bio(test_df, \"poi\"))\n",
    "print(\"Album entities in test_df:\", count_entities_bio(train_df, \"track\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
