{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71262df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer\n",
    "from seqeval.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model + tokenizer\n",
    "\n",
    "MODEL_DIR = \"snips_ner_model_full\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR)\n",
    "model.eval()\n",
    "\n",
    "# Label maps\n",
    "\n",
    "with open(\"ner_id2label.json\") as f:\n",
    "    id2label = {int(k): v for k, v in json.load(f).items()}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test CSV\n",
    "\n",
    "df = pd.read_csv(\"dataset/snips_ner_test.csv\")\n",
    "\n",
    "# Group into sentences\n",
    "\n",
    "def group_sentences(df):\n",
    "    sentences = []\n",
    "    for sent_id, grp in df.groupby(\"sentence_id\"):\n",
    "        grp = grp.sort_values(\"token_id\")\n",
    "        tokens = grp[\"token\"].tolist()\n",
    "        slots = grp[\"slot\"].tolist()\n",
    "        sentences.append({\"tokens\": tokens, \"slots\": slots})\n",
    "    return sentences\n",
    "\n",
    "test_sentences = group_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build encodings (re-tokenize so we get word_ids())\n",
    "\n",
    "def build_encodings(sentences, tokenizer, label2id, max_len=64):\n",
    "    all_tokens = [s[\"tokens\"] for s in sentences]\n",
    "    all_slots  = [s[\"slots\"]  for s in sentences]\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        all_tokens,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, slots in enumerate(all_slots):\n",
    "        word_ids = encodings.word_ids(batch_index=i)\n",
    "        seq = []\n",
    "        prev_wid = None\n",
    "\n",
    "        for wid in word_ids:\n",
    "            if wid is None:\n",
    "                seq.append(-100)\n",
    "            else:\n",
    "                label = slots[wid]\n",
    "\n",
    "                # SAME SUBWORD LOGIC AS TRAINING\n",
    "                if wid != prev_wid:\n",
    "                    seq.append(label2id[label])\n",
    "                else:\n",
    "                    if label.startswith(\"B-\"):\n",
    "                        label = \"I-\" + label[2:]\n",
    "                    seq.append(label2id[label])\n",
    "\n",
    "                prev_wid = wid\n",
    "\n",
    "        labels.append(seq)\n",
    "\n",
    "    return encodings, torch.tensor(labels)\n",
    "\n",
    "test_encodings, test_labels = build_encodings(test_sentences, tokenizer, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Dataset\n",
    "\n",
    "class NerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "test_dataset = NerDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions back to labels\n",
    "\n",
    "def decode_predictions(encodings, labels, pred_ids, id2label):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        true_seq = []\n",
    "        pred_seq = []\n",
    "\n",
    "        word_ids = encodings.word_ids(batch_index=i)\n",
    "\n",
    "        for j, wid in enumerate(word_ids):\n",
    "            if wid is None:\n",
    "                continue\n",
    "            if labels[i][j].item() == -100:\n",
    "                continue\n",
    "\n",
    "            true_label = id2label[int(labels[i][j])]\n",
    "            pred_label = id2label[int(pred_ids[i][j])]\n",
    "\n",
    "            true_seq.append(true_label)\n",
    "            pred_seq.append(pred_label)\n",
    "\n",
    "        y_true.append(true_seq)\n",
    "        y_pred.append(pred_seq)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55979a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pradhyumnaa G\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SEQEVAL NER REPORT =====\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                     album       0.00      0.00      0.00        13\n",
      "                    artist       0.93      0.95      0.94       109\n",
      "               best_rating       1.00      1.00      1.00        51\n",
      "                      city       0.93      0.92      0.92        71\n",
      "     condition_description       0.96      1.00      0.98        22\n",
      "     condition_temperature       1.00      1.00      1.00        21\n",
      "                   country       0.98      0.95      0.97        44\n",
      "                   cuisine       1.00      0.91      0.95        11\n",
      "          current_location       1.00      0.94      0.97        17\n",
      "               entity_name       0.65      0.72      0.68        18\n",
      "                  facility       1.00      1.00      1.00         7\n",
      "                     genre       0.29      0.67      0.40         3\n",
      "            geographic_poi       1.00      1.00      1.00        16\n",
      "             location_name       1.00      1.00      1.00        29\n",
      "                movie_name       0.93      0.86      0.89        49\n",
      "                movie_type       0.96      1.00      0.98        24\n",
      "                music_item       0.93      0.97      0.95        86\n",
      "      object_location_type       1.00      1.00      1.00        20\n",
      "               object_name       0.87      0.91      0.89       151\n",
      "object_part_of_series_type       1.00      1.00      1.00        15\n",
      "             object_select       0.96      0.96      0.96        49\n",
      "               object_type       0.99      1.00      1.00       155\n",
      "    party_size_description       1.00      1.00      1.00        13\n",
      "         party_size_number       1.00      1.00      1.00        57\n",
      "                  playlist       0.93      0.92      0.92       109\n",
      "            playlist_owner       1.00      0.98      0.99        54\n",
      "                       poi       0.33      0.50      0.40         6\n",
      "               rating_unit       0.98      1.00      0.99        61\n",
      "              rating_value       1.00      1.00      1.00       100\n",
      "           restaurant_name       0.86      0.95      0.90        20\n",
      "           restaurant_type       0.94      0.95      0.94        62\n",
      "               served_dish       0.83      1.00      0.91         5\n",
      "                   service       1.00      1.00      1.00        39\n",
      "                      sort       1.00      0.96      0.98        26\n",
      "          spatial_relation       0.97      0.97      0.97        67\n",
      "                     state       0.96      0.98      0.97        51\n",
      "                 timeRange       0.96      0.99      0.97       110\n",
      "                     track       0.21      0.50      0.30         6\n",
      "                      year       1.00      1.00      1.00        25\n",
      "\n",
      "                 micro avg       0.94      0.95      0.95      1792\n",
      "                 macro avg       0.88      0.91      0.89      1792\n",
      "              weighted avg       0.94      0.95      0.95      1792\n",
      "\n",
      "Entity-Level F1: 0.9454746747854967\n"
     ]
    }
   ],
   "source": [
    "# Run predictions\n",
    "\n",
    "trainer = Trainer(model=model)\n",
    "\n",
    "preds = trainer.predict(test_dataset)\n",
    "logits = preds.predictions\n",
    "pred_ids = np.argmax(logits, axis=-1)\n",
    "\n",
    "y_true, y_pred = decode_predictions(\n",
    "    test_encodings, test_labels, pred_ids, id2label\n",
    ")\n",
    "\n",
    "# Final SEQEVAL evaluation\n",
    "\n",
    "print(\"\\n===== SEQEVAL NER REPORT =====\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"Entity-Level F1:\", f1_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
